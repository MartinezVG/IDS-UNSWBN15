{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import column_stack\n",
    "from pandas import read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "from scipy.stats import mode\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import cm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import classification_report,confusion_matrix, roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from joblib import dump\n",
    "from joblib import load\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 9\n",
    "params = {\n",
    "    'max_depth': 5,\n",
    "    'nthread' : 4,\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 1000,\n",
    "    'random_state':random_state,\n",
    "}\n",
    "seed = 7\n",
    "test_size = 0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matriz de Confusion\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo el archivo csv\n",
      "Concatenar los archivos\n"
     ]
    }
   ],
   "source": [
    "print('Leyendo el archivo csv')\n",
    "dataframe1 = pd.read_csv(\"D:\\\\jupyter\\\\csv\\\\UNSW_NB15_training-set.csv\")\n",
    "dataframe11 = pd.read_csv(\"D:\\\\jupyter\\\\csv\\\\UNSW_NB15_testing-set.csv\")\n",
    "print('Concatenar los archivos')\n",
    "df = pd.concat([dataframe1, dataframe11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop(['id','label'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['proto'] = df2['proto'].astype('category')\n",
    "df2['service'] = df2['service'].astype('category')\n",
    "df2['state'] = df2['state'].astype('category')\n",
    "df2['attack_cat'] = df2['attack_cat'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['proto', 'service', 'state', 'attack_cat'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_columns = df2.select_dtypes(['category']).columns\n",
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[cat_columns] = df2[cat_columns].apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(df2[df2['attack_cat'] == 6].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba = df2.head(20)\n",
    "df2.drop(df2.index[0:20],0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df2['attack_cat']\n",
    "X = df2.drop(columns=['attack_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi = Y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ataque = ['back','analy','fuzz','shell','recon','exploits','dos','worm','generic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(bi)):\n",
    "    df2[ataque[i]] = (df2['attack_cat'] == bi[i]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df2.iloc[:,43:52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [0,1,2,3,4,5,6,7,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "backdoor = X[['proto','ct_src_ltm','dur','sload','sbytes','smean','ct_srv_src','stcpb','ct_dst_ltm','dmean','dbytes','sjit','ct_dst_src_ltm','ackdat','synack']]\n",
    "analy = X[['proto','dur','sload','ct_src_ltm','sbytes','response_body_len','ct_dst_src_ltm','ct_dst_ltm','stcpb','dbytes','smean','ct_srv_src','ackdat','synack','sjit']]\n",
    "fuzz = X[['sbytes','smean','sload','dur','stcpb','ackdat','ct_dst_src_ltm','ct_srv_src','dtcpb','dmean','proto','synack','dbytes','dload','tcprtt']]\n",
    "shell  = X[['sbytes','smean','sload','dtcpb','ackdat','dload','stcpb','tcprtt','ct_srv_src','proto','ct_dst_src_ltm','djit','sjit','synack','ct_src_ltm']]\n",
    "recon = X[['sbytes','stcpb','dtcpb','synack','smean','dur','ackdat','sload','proto','djit','tcprtt','sjit','dload','dinpkt','ct_srv_src']]\n",
    "exploit = X[['sbytes','smean','dbytes','stcpb','dur','dmean','sload','dtcpb','dload','ackdat','djit','tcprtt','sjit','response_body_len','dinpkt']]\n",
    "dos = X[['sbytes','dtcpb','smean','dbytes','dur','stcpb','djit','ackdat','synack','dload','dmean','sload','sjit','tcprtt','response_body_len']]\n",
    "worm = X[['sbytes','smean','stcpb','dtcpb','sload','dload','synack','tcprtt','ackdat','ct_srv_src','dur','sinpkt','sttl','sjit','ct_src_ltm']]\n",
    "generic = X[['sbytes','smean','sload','ct_src_ltm','dur','stcpb','dtcpb','synack','dload','ackdat','dmean','dbytes','djit','ct_dst_src_ltm','proto']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BACKDOOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9874291141715786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[35288,    11],\n",
       "       [  439,    59]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(backdoor, Y.iloc[:, 0],\n",
    "test_size=test_size, random_state=seed)\n",
    "modelback = XGBClassifier(**params)\n",
    "modelback.fit(X_train, y_train)\n",
    "predictions = modelback.predict(X_test)\n",
    "print('Accuracy',accuracy_score(y_test,predictions))\n",
    "cm = confusion_matrix(y_test,predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersample = RandomUnderSampler(sampling_strategy='majority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_over, y_over = oversample.fit_resample(backdoor, Y.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8156370656370656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[409, 100],\n",
       "       [ 91, 436]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over,\n",
    "test_size=test_size, random_state=seed)\n",
    "modelback = XGBClassifier(**params)\n",
    "modelback.fit(X_train, y_train)\n",
    "predictions = modelback.predict(X_test)\n",
    "print('Accuracy',accuracy_score(y_test,predictions))\n",
    "cm = confusion_matrix(y_test,predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_sample(backdoor, Y.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9148206414671826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[29715,  5528],\n",
       "       [  482, 34832]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_res, y_train_res,\n",
    "test_size=test_size, random_state=seed)\n",
    "modelback = XGBClassifier(**params)\n",
    "modelback.fit(X_train, y_train)\n",
    "predictions = modelback.predict(X_test)\n",
    "print('Accuracy',accuracy_score(y_test,predictions))\n",
    "cm = confusion_matrix(y_test,predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9858368019666452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[35150,    30],\n",
       "       [  477,   140]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(analy, Y.iloc[:, 1],\n",
    "test_size=test_size, random_state=seed)\n",
    "modelanaly = XGBClassifier(**params)\n",
    "modelanaly.fit(X_train, y_train)\n",
    "predictions = modelanaly.predict(X_test)\n",
    "print('Accuracy',accuracy_score(y_test,predictions))\n",
    "cm = confusion_matrix(y_test,predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8233333333333334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[468, 130],\n",
       "       [ 82, 520]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_over, y_over = undersample.fit_resample(analy, Y.iloc[:, 1])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over,\n",
    "test_size=test_size, random_state=seed)\n",
    "modelback = XGBClassifier(**params)\n",
    "modelback.fit(X_train, y_train)\n",
    "predictions = modelback.predict(X_test)\n",
    "print('Accuracy',accuracy_score(y_test,predictions))\n",
    "cm = confusion_matrix(y_test,predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_sample(analy, Y.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.91896921568906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[29806,  5237],\n",
       "       [  467, 34883]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_res, y_train_res,\n",
    "test_size=test_size, random_state=seed)\n",
    "modelanaly = XGBClassifier(**params)\n",
    "modelanaly.fit(X_train, y_train)\n",
    "predictions = modelanaly.predict(X_test)\n",
    "print('Accuracy',accuracy_score(y_test,predictions))\n",
    "cm = confusion_matrix(y_test,predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8993491074671062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[32054,    66],\n",
       "       [ 3537,   140]], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dos, Y.iloc[:, 6],\n",
    "test_size=test_size, random_state=seed)\n",
    "modeldos = XGBClassifier(**params)\n",
    "modeldos.fit(X_train, y_train)\n",
    "predictions = modeldos.predict(X_test)\n",
    "print('Accuracy',accuracy_score(y_test,predictions))\n",
    "cm = confusion_matrix(y_test,predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    107057\n",
       "1     12264\n",
       "Name: dos, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.iloc[:,6].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8442723196086425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2771,  833],\n",
       "       [ 313, 3442]], dtype=int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_over, y_over = undersample.fit_resample(dos, Y.iloc[:, 6])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_over, y_over,\n",
    "test_size=test_size, random_state=seed)\n",
    "modeldos = XGBClassifier(**params)\n",
    "modeldos.fit(X_train, y_train)\n",
    "predictions = modeldos.predict(X_test)\n",
    "print('Accuracy',accuracy_score(y_test,predictions))\n",
    "cm = confusion_matrix(y_test,predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_sample(dos, Y.iloc[:, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8856853740172803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[25769,  6323],\n",
       "       [ 1020, 31123]], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_res, y_train_res,\n",
    "test_size=test_size, random_state=seed)\n",
    "modeldos = XGBClassifier(**params)\n",
    "modeldos.fit(X_train, y_train)\n",
    "predictions = modeldos.predict(X_test)\n",
    "print('Accuracy',accuracy_score(y_test,predictions))\n",
    "cm = confusion_matrix(y_test,predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reconn, Y.iloc[:, 4],\n",
    "test_size=test_size, random_state=seed)\n",
    "modelrecon = XGBClassifier(**params)\n",
    "modelrecon.fit(X_train, y_train)\n",
    "predictions = modeldos.predict(X_test)\n",
    "print('Accuracy',accuracy_score(y_test,predictions))\n",
    "cm = confusion_matrix(y_test,predictions)\n",
    "cm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
